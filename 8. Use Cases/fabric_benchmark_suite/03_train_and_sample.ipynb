{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0558babc-de7d-4294-8b1f-5c86ffd496eb",
   "metadata": {},
   "source": [
    "# Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5219609-fac0-4ec0-9ea0-6dbef4841bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install sdv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22bc2a8-9bbd-4875-9863-79cfa38d1f11",
   "metadata": {},
   "source": [
    "# Train models and generate sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5910b1e5-2ce4-4e5d-be0c-96e9bf577d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from ydata.metadata import Metadata\n",
    "from ydata.dataset import Dataset\n",
    "\n",
    "import sdv\n",
    "\n",
    "from common.sdv import fabric_to_sdv_metadata\n",
    "from common.config import *\n",
    "from common.utils import update_json_file, ndd, ndd_to_dict, load_dataframe, get_model_class\n",
    "\n",
    "\n",
    "def get_sample(model, nrows):\n",
    "    sample = model.sample(nrows)\n",
    "    if isinstance(sample, Dataset):\n",
    "        sample = sample.to_pandas()\n",
    "    return sample\n",
    "\n",
    "def resolve_init_params(init_params: Dict, metadata: Metadata):\n",
    "    c = ['metadata', 'table_metadata']\n",
    "    for e in c:\n",
    "        if e in init_params:\n",
    "            if init_params[e] == 'sdv':\n",
    "                init_params[e] = fabric_to_sdv_metadata(metadata)\n",
    "    return init_params\n",
    "\n",
    "def resolve_fit_params(fit_params: Dict, metadata: Metadata):\n",
    "    if 'metadata' in fit_params:\n",
    "        if fit_params['metadata'] == 'fabric':\n",
    "            fit_params['metadata'] = metadata\n",
    "    return fit_params\n",
    "\n",
    "\n",
    "def train_model(name: str, dataset, metadata: Metadata):\n",
    "    model_info = get_models_config()[name]\n",
    "    start = time.time()\n",
    "    model_csl = get_model_class(name)\n",
    "    init_params = resolve_init_params(model_info.get('init_params', {}), metadata)\n",
    "    model = model_csl(**init_params)\n",
    "    dataset_type = model_info.get('dataset')\n",
    "    X = dataset if dataset_type == 'pandas' else Dataset(dataset)\n",
    "    fit_params = resolve_fit_params(model_info.get('fit_params', {}), metadata)\n",
    "    model.fit(X, **fit_params)\n",
    "    end = time.time()\n",
    "    timer = end - start\n",
    "    return model, timer\n",
    "\n",
    "def load_model(name: str, path: str):\n",
    "    model_info = get_models_config()[name]\n",
    "    model_csl = get_model_class(name)\n",
    "    return model_csl.load(path)\n",
    "\n",
    "def train_and_sample_models():\n",
    "    datasets_config = get_datsets_config()\n",
    "    models_config = get_models_config()\n",
    "    analysis_config = get_analysis_config()\n",
    "\n",
    "    timers = ndd()\n",
    "    for dataset_name in datasets_config.keys():\n",
    "        print(f'# Dataset: {dataset_name} ')\n",
    "        dataset = load_dataframe(dataset_name, split='train')\n",
    "        metadata = Metadata.load(str(Path(DATASET_PATH) / f'{dataset_name}_train.metadata.pkl'))\n",
    "        for model_name, model_info in models_config.items():\n",
    "            if not model_info.get('enabled', True):\n",
    "                continue\n",
    "            try:\n",
    "                # Training\n",
    "                print(f' # Model: {model_name} ')\n",
    "                model_path = Path(MODELS_PATH) / f'{model_name}_{dataset_name}.pkl'\n",
    "                if os.path.isfile(model_path):\n",
    "                    print(\"  -> Load model...\")\n",
    "                    model = load_model(model_name, model_path)\n",
    "                else:\n",
    "                    print(\"  -> Train model...\")\n",
    "                    model, timer = train_model(model_name, dataset, metadata)\n",
    "                    timers[dataset_name][model_name]['training'] = timer\n",
    "                    model.save(model_path)\n",
    "                    print(f'   Training time: {timer}')\n",
    "\n",
    "                # Sampling\n",
    "                sample_path = Path(SAMPLES_PATH) / f'{model_name}_{dataset_name}_sample.csv'\n",
    "                if os.path.isfile(sample_path):\n",
    "                    print(\"  -> Skip as sample exists...\")\n",
    "                else:\n",
    "                    print(\"  -> Generate sample...\")\n",
    "                    holdout = load_dataframe(dataset_name, split='holdout')\n",
    "                    start = time.time()\n",
    "                    sample = get_sample(model, holdout.shape[0])\n",
    "                    end = time.time()\n",
    "                    timer = end - start\n",
    "                    timers[dataset_name][model_name]['sample'] = timer\n",
    "                    sample.to_csv(sample_path, index=False)\n",
    "                    print(f'   Sampling time: {timer}')\n",
    "                path = analysis_config['output_files']['timers']\n",
    "                update_json_file(path, ndd_to_dict(timers))\n",
    "            except Exception as e:\n",
    "                print('Could no train and sample the synthsizer')\n",
    "                print(e)\n",
    "    return ndd_to_dict(timers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5da0eb-ee51-4d84-9aab-2ab715e03bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Dataset: sdv.adult \n",
      " # Model: fabric.regular \n",
      "  -> Train model...\n",
      "INFO: 2022-12-02 15:27:19,249 [SYNTHESIZER] - Number columns considered for synth: 15\n",
      "INFO: 2022-12-02 15:31:06,806 [SYNTHESIZER] - Starting the synthetic data modeling process over 1x1 blocks.\n",
      "INFO: 2022-12-02 15:31:06,815 [SYNTHESIZER] - Preprocess segment\n",
      "INFO: 2022-12-02 15:31:06,819 [SYNTHESIZER] - Synthesizer init.\n",
      "INFO: 2022-12-02 15:31:06,820 [SYNTHESIZER] - Processing the data prior fitting the synthesizer.\n",
      "   Training time: 231.98067355155945\n",
      "  -> Generate sample...\n",
      "INFO: 2022-12-02 15:31:10,750 [SYNTHESIZER] - Start generating model samples.\n",
      "   Sampling time: 2.8316285610198975\n",
      "sdv.adult {} {'fabric.regular': {'training': 231.98067355155945, 'sample': 2.8316285610198975}}\n",
      " # Model: sdv.tabular \n",
      "  -> Train model...\n",
      "INFO: 2022-12-02 15:31:13,841 Fitting table None metadata\n",
      "INFO: 2022-12-02 15:31:13,846 Anonymizing table None\n",
      "INFO: 2022-12-02 15:31:13,847 Fitting constraints for table None\n",
      "INFO: 2022-12-02 15:31:13,848 Fitting HyperTransformer for table None\n",
      "INFO: 2022-12-02 15:31:14,419 Fitting GaussianMultivariate(distribution=\"{'age.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'workclass.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'fnlwgt.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'education.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'education-num.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'marital-status.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'occupation.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'relationship.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'race.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'sex.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'capital-gain.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'capital-loss.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'hours-per-week.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'native-country.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>, 'label.value': <class 'copulas.univariate.gaussian.GaussianUnivariate'>}\")\n",
      "   Training time: 0.7253715991973877\n",
      "  -> Generate sample...\n",
      "   Sampling time: 0.4416840076446533\n",
      "training {'training': 231.98067355155945, 'sample': 2.8316285610198975} 231.98067355155945\n",
      "sample {'training': 231.98067355155945, 'sample': 2.8316285610198975} 2.8316285610198975\n",
      "sdv.tabular {'fabric.regular': {'training': 231.98067355155945, 'sample': 2.8316285610198975}} {'training': 0.7253715991973877, 'sample': 0.4416840076446533}\n"
     ]
    }
   ],
   "source": [
    "if os.environ.get('STEP_DISABLED') is None:\n",
    "    timers = train_and_sample_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be41a090-daf4-45b2-bde5-1dafe0e1e508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training {'training': 231.98067355155945, 'sample': 2.8316285610198975} 231.98067355155945\n",
      "sample {'training': 231.98067355155945, 'sample': 2.8316285610198975} 2.8316285610198975\n",
      "training {'training': 0.7253715991973877, 'sample': 0.4416840076446533} 0.7253715991973877\n",
      "sample {'training': 0.7253715991973877, 'sample': 0.4416840076446533} 0.4416840076446533\n"
     ]
    }
   ],
   "source": [
    "from common.config import get_analysis_config\n",
    "from common.utils import update_json_file\n",
    "\n",
    "if os.environ.get('STEP_DISABLED') is None:\n",
    "    analysis_config = get_analysis_config()\n",
    "\n",
    "    path = analysis_config['output_files']['timers']\n",
    "    update_json_file(path, timers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
