{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc16183f-815b-41f7-8aed-7cada2b431c9",
   "metadata": {},
   "source": [
    "# 5 - Train and Classify on original data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9d30a-0832-453c-a63a-7d312f584bc7",
   "metadata": {},
   "source": [
    "## 0 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ace2b31-9905-4483-a9a4-aa082773cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from pandas import DataFrame\n",
    "\n",
    "from ydata.connectors import LocalConnector\n",
    "from ydata.connectors.filetype import FileType\n",
    "from ydata.utils.formats import read_json\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a39da9-cf7b-4400-86e0-4cc8ff0fc9b2",
   "metadata": {},
   "source": [
    "## 1 - Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78e7e584-9b43-4ce6-961d-f7d8b87b71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the YData's connector\n",
    "connector = LocalConnector()\n",
    "\n",
    "# Read the data \n",
    "orig_df = connector.read_file('data_processed.csv', file_type = FileType.CSV).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b218ac-481e-4eef-8b65-40f84040281c",
   "metadata": {},
   "source": [
    "## 2 - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f795fb-0c87-45be-adb1-d80690389992",
   "metadata": {},
   "source": [
    "### 2.1 - Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b0f009e-031c-40bc-b557-1f05f2aab9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "x_train, x_test = train_test_split(orig_df, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d072e079-4eaa-4823-815f-7f04e692d379",
   "metadata": {},
   "source": [
    "### 2.2 - Train and Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09a82661-7632-42d1-9b1c-3e573d7e17f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classifier and predict results\n",
    "orig_tree_clf = DecisionTreeClassifier(random_state=4)\n",
    "orig_tree_clf.fit(x_train.drop('Unusual', axis=1), x_train['Unusual'])\n",
    "preds = orig_tree_clf.predict(x_test.drop('Unusual', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac76c30-16e1-42f0-885f-c43f76eadc6c",
   "metadata": {},
   "source": [
    "### 2.3 - Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1613766-e90a-46b3-b231-c653d2d84709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the scores\n",
    "acc = accuracy_score(x_test['Unusual'].values, preds)\n",
    "f1 = f1_score(x_test['Unusual'].values, preds)\n",
    "recall = recall_score(x_test['Unusual'].values, preds)\n",
    "precision = precision_score(x_test['Unusual'].values, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e27aaf-c34d-4a3c-a5b1-1262194aaba8",
   "metadata": {},
   "source": [
    "## 3 - Create Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0118e06f-7cd2-4ef1-af87-60021a5ed6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Artifact. The table with the metrics will be shown on the \"Run Output\"  section of the \"Runs\". \n",
    "metrics = {\n",
    "    'metrics': [\n",
    "        {\n",
    "            'name': 'Accuracy-score',\n",
    "            'numberValue':  acc,\n",
    "            'format': 'PERCENTAGE'\n",
    "        },\n",
    "        {\n",
    "            'name': 'F1-score',\n",
    "            'numberValue':  f1,\n",
    "            'format': 'PERCENTAGE'\n",
    "        },\n",
    "         {\n",
    "            'name': 'Recall',\n",
    "            'numberValue':  recall,\n",
    "            'format': 'PERCENTAGE'\n",
    "        },\n",
    "         {\n",
    "            'name': 'Precision',\n",
    "            'numberValue':  precision,\n",
    "            'format': 'PERCENTAGE'\n",
    "        }\n",
    "    ]\n",
    "  }\n",
    "\n",
    "with open(\"mlpipeline-metrics.json\", 'w') as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fcb8f986-d575-4f33-9a36-da7e8d8bbd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "pos_neg = confusion_matrix(x_test['Unusual'].values, preds).ravel()\n",
    "\n",
    "matrix = [\n",
    "    ['normal', 'normal', pos_neg[0]],\n",
    "    ['normal', 'unusual', pos_neg[1]],\n",
    "    ['unusual', 'normal', pos_neg[2]],\n",
    "    ['unusual', 'unusual', pos_neg[3]]\n",
    "]\n",
    "\n",
    "df = DataFrame(matrix,columns=['target','predicted','count'])\n",
    "\n",
    "metadata = {\n",
    "    \"outputs\": [\n",
    "        {\n",
    "            \"type\": \"confusion_matrix\",\n",
    "            \"format\": \"csv\",\n",
    "            \"schema\": [\n",
    "                {\n",
    "                    \"name\": \"target\",\n",
    "                    \"type\": \"CATEGORY\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"predicted\",\n",
    "                    \"type\": \"CATEGORY\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"count\",\n",
    "                    \"type\": \"NUMBER\"\n",
    "                }\n",
    "            ],\n",
    "            \"source\": df.to_csv(header=False, index=False),\n",
    "            \"storage\": \"inline\",\n",
    "            \"labels\": [\n",
    "                \"normal\",\n",
    "                \"unusual\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('mlpipeline-ui-metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b25d4-0af8-48e2-a63d-00630c8b96cd",
   "metadata": {},
   "source": [
    "## 4 - Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30ab1f-c3fe-44d4-9c94-4cd076aabe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass onto the next pipeline the test set \n",
    "x_test.index.name = 'test_ind'\n",
    "x_test.reset_index(inplace=True)\n",
    "connector.write_file(data=x_test, path='test_set.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
