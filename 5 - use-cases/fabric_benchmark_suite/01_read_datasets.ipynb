{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7baf3000-7d44-4ec2-b137-aefc95c1caea",
   "metadata": {
    "papermill": {
     "duration": 0.042861,
     "end_time": "2022-11-25T14:00:42.129409",
     "exception": false,
     "start_time": "2022-11-25T14:00:42.086548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load and store the datasets\n",
    "\n",
    "Because other libraries such as SDV uses pandas, we save a copy of the dataset in CSV to re-use in other steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342150f8-6108-4e93-a71b-327dd9c2ddd6",
   "metadata": {
    "papermill": {
     "duration": 0.097269,
     "end_time": "2022-11-25T14:00:42.267961",
     "exception": false,
     "start_time": "2022-11-25T14:00:42.170692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from common.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c031483-e3ca-4e89-9ba6-d4a9768070a0",
   "metadata": {
    "papermill": {
     "duration": 1.490702,
     "end_time": "2022-11-25T14:00:43.801152",
     "exception": false,
     "start_time": "2022-11-25T14:00:42.310450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read data from SDV\n",
    "SDV_BASE_URL = \"https://sdv-datasets.s3.amazonaws.com\"\n",
    "\n",
    "datasets_config = get_datsets_config()\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "from ydata.connectors import GCSConnector\n",
    "from ydata.connectors.filetype import FileType\n",
    "from ydata.dataset import Dataset\n",
    "from ydata.utils.formats import read_json\n",
    "\n",
    "\n",
    "def get_from_gcs(gs_filepath, credential_path=CREDENTIALS_PATH):\n",
    "    token = read_json(credential_path)\n",
    "    connector = GCSConnector(\"ydatasynthetic\", keyfile_dict=token)\n",
    "    return connector.read_file(gs_filepath, file_type=FileType.CSV)\n",
    "\n",
    "def download_sdv_dataset(dataset_info, output_folder = Path(DOWNLOADED_DATASETS)):\n",
    "    if dataset_info.get('origin') == 'sdv':\n",
    "        output_file_path = output_folder / f\"{dataset_info['name']}.zip\"\n",
    "        print(output_file_path)\n",
    "        urllib.request.urlretrieve(f\"{SDV_BASE_URL}/{dataset_info['name']}.zip\", output_file_path)\n",
    "        with zipfile.ZipFile(output_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(output_folder)\n",
    "\n",
    "def get_sdv_dataset(dataset_info, as_fabric: bool = True, output_folder = Path(DOWNLOADED_DATASETS)):\n",
    "    data_file = output_folder / f\"{dataset_info['name']}\" /  f\"{dataset_info['name']}.csv\"\n",
    "    if not Path(data_file).is_file():\n",
    "        download_sdv_dataset(dataset_info, output_folder = Path(DOWNLOADED_DATASETS))\n",
    "    data = read_csv(data_file)\n",
    "    return Dataset(data) if as_fabric else data\n",
    "            \n",
    "def get_fabric_dataset(dataset_info: str, credential_path=None):\n",
    "    if 'url' in dataset_info:\n",
    "        # For now I assume GCS\n",
    "        return get_from_gcs(dataset_info['url'], credential_path=credential_path)\n",
    "    else:  # Assume it is from the platform\n",
    "        datasource = DataSources.get(uid=dataset_info['uuid'], namespace=dataset_info['namespace'])\n",
    "        return datasource.read() \n",
    "                \n",
    "def get_dataset(name: str, as_fabric=True, credential_path=CREDENTIALS_PATH, output_folder=Path(DOWNLOADED_DATASETS)):\n",
    "    datasets_config = get_datsets_config()                          \n",
    "    if name not in datasets_config:\n",
    "        raise Exception(\"Unknown dataset\")\n",
    "    dataset_info = datasets_config[name]\n",
    "    if dataset_info.get('origin') in [None, 'fabric']:\n",
    "        dataset = get_fabric_dataset(dataset_info, credential_path=credential_path)\n",
    "        return dataset if as_fabric else dataset.to_pandas()\n",
    "    elif dataset_info.get('origin') == 'sdv':\n",
    "        return get_sdv_dataset(dataset_info, as_fabric=as_fabric, output_folder=output_folder)\n",
    "    else:\n",
    "        raise Exception(\"Unknown origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15991de3-d4db-4ece-8846-63c181212ac3",
   "metadata": {
    "papermill": {
     "duration": 0.117476,
     "end_time": "2022-11-25T14:00:43.961368",
     "exception": false,
     "start_time": "2022-11-25T14:00:43.843892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Get sdv.adult\n",
      " -> Skip as already exists localy...\n"
     ]
    }
   ],
   "source": [
    "datsets_config = get_datsets_config()\n",
    "\n",
    "for name in datsets_config.keys():\n",
    "    print(f'# Get {name}')\n",
    "    dataset_path = Path(DATASET_PATH) / f'{name}.csv'\n",
    "    if os.path.isfile(dataset_path):\n",
    "        print(' -> Skip as already exists localy...')\n",
    "    else:\n",
    "        dataset = get_dataset(name)\n",
    "        dataset = dataset.to_pandas() \n",
    "        dataset.columns = [c.strip() for c in dataset.columns]\n",
    "        dataset.to_csv(dataset_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef88704-9771-46ef-8a46-05dbc989a352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.265464,
   "end_time": "2022-11-25T14:00:44.419290",
   "environment_variables": {},
   "exception": null,
   "input_path": "/mnt/laboratory/cffb5f6a-e61a-4bcb-bc00-cec45a1553dd/01_read_datasets.ipynb",
   "output_path": "/mnt/laboratory/cffb5f6a-e61a-4bcb-bc00-cec45a1553dd/01_read_datasets.ipynb",
   "parameters": {},
   "start_time": "2022-11-25T14:00:41.153826",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
