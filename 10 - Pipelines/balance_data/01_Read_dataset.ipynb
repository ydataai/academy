{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a676f1-a811-4a60-9786-b2a11fc7e5fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T22:46:12.358397Z",
     "iopub.status.busy": "2022-09-05T22:46:12.357479Z",
     "iopub.status.idle": "2022-09-05T22:46:12.362365Z",
     "shell.execute_reply": "2022-09-05T22:46:12.361701Z"
    },
    "papermill": {
     "duration": 0.041868,
     "end_time": "2022-12-08T19:15:50.016528",
     "exception": false,
     "start_time": "2022-12-08T19:15:49.974660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Dataset balancing with synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faf5f68",
   "metadata": {
    "papermill": {
     "duration": 0.040368,
     "end_time": "2022-12-08T19:15:50.099387",
     "exception": false,
     "start_time": "2022-12-08T19:15:50.059019",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "This set of notebooks is meant to serve as guideline and quickstart for the development of a classifier for imbalanced data. The pipeline template includes the following steps and notebooks:\n",
    "\n",
    "- **Read dataset**\n",
    "    - Consume a datasource created in the UI\n",
    "- **Data profiling**\n",
    "    - Profile the created dataset to extract summary statistics and other metrics, that can be used further down the development, for either de definition of constrains or rules implementation\n",
    "- **Synthetic data generation & merge with real data**\n",
    "    - Generation of synthetic records from the class identified as being the least represented\n",
    "- **Classifier training**\n",
    "    - Training of a classifier based on the prepared & balanced dataset\n",
    "- **Validation of the results in a holdout set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ccb94",
   "metadata": {
    "papermill": {
     "duration": 0.042582,
     "end_time": "2022-12-08T19:15:50.181561",
     "exception": false,
     "start_time": "2022-12-08T19:15:50.138979",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Read the data\n",
    "\n",
    "The first step is to read the data. As Data Scientists it is usual to find the use of CSV as the main data sources. For that reason we enable a flexible interface to consume CSV data.\n",
    "\n",
    "- Through YData SDK - LocalConnector - this method returns automatically a Dataset object that is ready to be consumed in downstream applications such as Synthetisizer.\n",
    "- Leveraging pandas - Pandas is available in YData image. This method requires the data to be converted into Dataset, if the user wants to leverage downstream applications such as Synthesizers, or the scale from our distributed computing engine.\n",
    "\n",
    "In this particular example, we have decided to load the data while using pandas SDK method `read_csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08918b8a-a05f-496d-9e66-6ca49449ff3e",
   "metadata": {
    "papermill": {
     "duration": 0.043251,
     "end_time": "2022-12-08T19:15:50.265106",
     "exception": false,
     "start_time": "2022-12-08T19:15:50.221855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a63de2-d443-4bd9-a065-cd85759b7e0e",
   "metadata": {
    "papermill": {
     "duration": 2.364569,
     "end_time": "2022-12-08T19:15:52.672134",
     "exception": false,
     "start_time": "2022-12-08T19:15:50.307565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ydata.utils.formats import read_json\n",
    "from ydata.dataset import Dataset\n",
    "from ydata.metadata import Metadata\n",
    "from ydata.labs.datasources import DataSources\n",
    "\n",
    "from ydata.connectors.filetype import FileType\n",
    "from ydata.connectors import GCSConnector\n",
    "\n",
    "from ydata.dataset.holdout import Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c0e416-786a-4cf9-bbf5-5383246a9c23",
   "metadata": {
    "papermill": {
     "duration": 0.041629,
     "end_time": "2022-12-08T19:15:52.756405",
     "exception": false,
     "start_time": "2022-12-08T19:15:52.714776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Read the data from an existing source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5297fb6e-2d77-460e-9bf6-09177872a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = os.getenv('datasetid', 'b9cc0c94-f9b9-4dd9-9893-113e6f5244a5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd392e34-4ed3-41fc-bd44-941a4e026dbe",
   "metadata": {
    "papermill": {
     "duration": 12.550591,
     "end_time": "2022-12-08T19:16:05.351495",
     "exception": false,
     "start_time": "2022-12-08T19:15:52.800904",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 5.02 ss\n",
      "[########################################] | 100% Completed | 4.83 sms\n",
      "[########################################] | 100% Completed | 7.50 ss\n",
      "[########################################] | 100% Completed | 35.86 s\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSources.get(uid=dataset_id).read()\n",
    "\n",
    "metadata = Metadata(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1718ed4-2846-4a45-82b8-015202563463",
   "metadata": {},
   "source": [
    "In case any datatype is not correctly identified, it is recommend to udpate the Metadata\n",
    "The way data type are chosen, can impact the quality of the synthetic data generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbf48a6f-8fad-40c6-9ada-ddb391955481",
   "metadata": {
    "papermill": {
     "duration": 0.057831,
     "end_time": "2022-12-08T19:16:05.825714",
     "exception": false,
     "start_time": "2022-12-08T19:16:05.767883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata.update_datatypes({'Class': 'categorical'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5533a97a",
   "metadata": {
    "papermill": {
     "duration": 0.046203,
     "end_time": "2022-12-08T19:16:05.916739",
     "exception": false,
     "start_time": "2022-12-08T19:16:05.870536",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Preparing the data for the workflow\n",
    "Now that we have our dataset ready to start working, before any data analysis and preparation it is always recommended to create a holdout. This ensures unbiased results in terms of improvements achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf60e016-2019-4175-8b19-d43dee95aef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ydata.metadata.metadata.Metadata'>\n"
     ]
    }
   ],
   "source": [
    "print(type(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a02ca02d-5355-4854-9bd7-c5ce60e078a9",
   "metadata": {
    "papermill": {
     "duration": 9.131178,
     "end_time": "2022-12-08T19:16:15.094851",
     "exception": false,
     "start_time": "2022-12-08T19:16:05.963673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "holdout = Holdout()\n",
    "train, test = holdout.get_split(dataset, metadata, strategy='stratified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3495c427-33c6-4115-bc94-95112a96ca14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ydata.metadata.metadata.Metadata at 0x7f2935662980>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce11e60d-02c0-49ab-b47e-b5ff98f6a41f",
   "metadata": {
    "papermill": {
     "duration": 209.289149,
     "end_time": "2022-12-08T19:19:44.433613",
     "exception": false,
     "start_time": "2022-12-08T19:16:15.144464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 4.87 ss\n",
      "[########################################] | 100% Completed | 4.26 sms\n",
      "[########################################] | 100% Completed | 5.82 ss\n",
      "[########################################] | 100% Completed | 28.42 s\n"
     ]
    }
   ],
   "source": [
    "metadata_train = Metadata(train)\n",
    "metadata_train.update_datatypes({'Class':'categorical'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff098b0-725e-4e63-b0e4-ed3fc9cc3e6a",
   "metadata": {},
   "source": [
    "Pipelines are able to output results for each an every step. In this case, we've decided to output the metadata identified warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b64e59-3ed3-48be-a583-b8194c6e6187",
   "metadata": {
    "papermill": {
     "duration": 0.059489,
     "end_time": "2022-12-08T19:19:44.759935",
     "exception": false,
     "start_time": "2022-12-08T19:19:44.700446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings=[]\n",
    "for warning, val in metadata.warnings.items():\n",
    "    for col in val:\n",
    "        try:\n",
    "            level = col.details['level'].name\n",
    "            value = round(col.details['value'], 4)\n",
    "        except:\n",
    "            level = None\n",
    "            value = None\n",
    "        warnings.append({'warning': warning, 'column': col.column, 'level': level, 'value':value})\n",
    "\n",
    "df_warnings= pd.DataFrame(warnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ecf980-edf0-4135-a541-73bb9c08f921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T22:46:16.495431Z",
     "iopub.status.busy": "2022-09-05T22:46:16.494648Z",
     "iopub.status.idle": "2022-09-05T22:46:16.498307Z",
     "shell.execute_reply": "2022-09-05T22:46:16.497592Z"
    },
    "papermill": {
     "duration": 0.043495,
     "end_time": "2022-12-08T19:19:44.847056",
     "exception": false,
     "start_time": "2022-12-08T19:19:44.803561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create pipeline outputs\n",
    "Setting our pipeline outputs to share data and artifacts in-between the different steps of the pipeline, as well as for visualization.\n",
    "\n",
    "### Outputs\n",
    "Depending on the data volume datasets can also be stored in removed storages such as Google Cloud Storage of RDMBS. \n",
    "If they are small, they can be saved as pipelines temporary objects (CSV or pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "131ad374-9a13-44bb-8e9a-c4e62ad96ef1",
   "metadata": {
    "papermill": {
     "duration": 4.349743,
     "end_time": "2022-12-08T19:19:49.246571",
     "exception": false,
     "start_time": "2022-12-08T19:19:44.896828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Save the train metadata as a pickle file\n",
    "metadata_train.save('metadata.pkl')\n",
    "\n",
    "#Save the train dataset as a CSV or Pickle file\n",
    "train.to_pandas().to_csv('train.csv')\n",
    "\n",
    "#Save the holdout set as a CSV or Pickle file. \n",
    "test.to_pandas().to_csv('holdout.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07018e2-1d55-4d72-a724-068bc06f97e6",
   "metadata": {
    "papermill": {
     "duration": 0.042443,
     "end_time": "2022-12-08T19:19:49.333954",
     "exception": false,
     "start_time": "2022-12-08T19:19:49.291511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c08efaf-cc84-4d32-be7a-cda1f7a28cbb",
   "metadata": {
    "papermill": {
     "duration": 0.097759,
     "end_time": "2022-12-08T19:19:49.477883",
     "exception": false,
     "start_time": "2022-12-08T19:19:49.380124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "metadata = {\n",
    "    'outputs' : [\n",
    "        {\n",
    "      'type': 'table',\n",
    "      'storage': 'inline',\n",
    "      'format': 'csv',\n",
    "      'header': list(df_warnings.columns),\n",
    "      'source': df_warnings.to_csv(header=False, index=False)\n",
    "    }\n",
    "    ]\n",
    "  }\n",
    "\n",
    "with open('mlpipeline-ui-metadata.json', 'w') as metadata_file:\n",
    "    json.dump(metadata, metadata_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 241.457973,
   "end_time": "2022-12-08T19:19:50.239052",
   "environment_variables": {},
   "exception": null,
   "input_path": "/mnt/laboratory/b81ae1d3-8ba3-4f83-a6c3-facf4f6b8e19/01_Read_dataset.ipynb",
   "output_path": "/mnt/laboratory/b81ae1d3-8ba3-4f83-a6c3-facf4f6b8e19/01_Read_dataset.ipynb",
   "parameters": {},
   "start_time": "2022-12-08T19:15:48.781079",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
