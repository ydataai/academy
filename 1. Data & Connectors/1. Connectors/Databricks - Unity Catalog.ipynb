{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c9bf11-14ea-47f7-9991-41cadba5dbe6",
   "metadata": {},
   "source": [
    "# Connectors - Databricks Unity Catalog\n",
    "\n",
    "[YData SDK provides a seamless integration with Databricks Delta Lake](https://ydata.ai), allowing you to connect,\n",
    "query, and align with data resources between [ydata-sdk](https://pypi.org/project/ydata-sdk/) and Unity Catalog. This section will guide you through the benefits,\n",
    "setup, and usage of the Databricks' connector within ydata-sdk.\n",
    "\n",
    "### Benefits of Integration\n",
    "Integrating ydata-sdk with Databricks offers several key benefits:\n",
    "\n",
    "- **Enhanced Data Accessibility:** Seamlessly access and integrate previously siloed data.\n",
    "- **Improved Data Quality:** Use YData's tools to enhance the quality of your data through data preparation and augmentation.\n",
    "- **Scalability:** Leverage Databricks' robust infrastructure to scale data processing and AI workloads.\n",
    "- **Streamlined Workflows:** Simplify data workflows with connectors and SDKs, reducing manual effort and potential errors.\n",
    "- **Comprehensive Support:** Benefit from extensive documentation and support for both platforms, ensuring smooth integration and operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d358cb66-0916-4e24-8c3e-9ebbe89c1cbc",
   "metadata": {},
   "source": "### Authenticate with your account YData"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Authenticate with your ydata-sdk token - https://dashboard.ydata.ai/\n",
    "import os\n",
    "\n",
    "os.environ['YDATA_LICENSE_KEY'] = '{add-your-key}'"
   ],
   "id": "85da668fcf3c819e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create a Unity Catalog connector\n",
    "\n",
    "Databricks Unity Catalog leverages the concept of [Delta Sharing](https://www.databricks.com/product/delta-sharing), meaning this is a great way not only to ensure alignment between Catalogs but also to limit the access to data. This means that byt leveraging the Unity Catalog connector, users can only access a set of data assets that were authorized for a given Share.\n"
   ],
   "id": "1c66210315422f6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ydata.connectors import DatabricksUnityCatalog\n",
    "\n",
    "SHARE_NAME='insert-share-name'\n",
    "SCHEMA_NAME='insert-schema-name'\n",
    "TABLE_NAME='insert-table-name'\n",
    "\n",
    "connector = DatabricksUnityCatalog(profile='insert-file-path')"
   ],
   "id": "c1b56a661740a6e6"
  },
  {
   "cell_type": "markdown",
   "id": "3475cf67-7217-4959-a489-85b1a486a5c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read from you create Delta Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ba8e557-979e-45c6-85c4-85268ffd66c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['teste']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List the available shares for the provided authentication\n",
    "connector.list_shares()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d705dc26-1d36-4f46-b13b-50936420aaab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['berka']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List the available schemas for a given share\n",
    "connector.list_schemas(share_name='teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcff5c7f-984b-4445-8b4d-7d2e706c8084",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transactions', 'trans_drift_metrics', 'trans_profile_metrics']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List the available tables for a given schema in a share\n",
    "connector.list_tables(schema_name='berka',\n",
    "                       share_name='teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8381ca0d-af4b-4ff8-af4a-3f3aed9eb3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transactions': {'share': 'teste', 'schema': 'berka'},\n",
       " 'trans_drift_metrics': {'share': 'teste', 'schema': 'berka'},\n",
       " 'trans_profile_metrics': {'share': 'teste', 'schema': 'berka'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List all the tables regardless of share and schema\n",
    "connector.list_all_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f76f8b-1a8b-4606-a4c1-9ba90343daa7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read from you create Delta Share\n",
    "\n",
    "Using the Unity Catalog connector it is possible to:\n",
    "- Get a table from a Delta Share\n",
    "- Get a sample from a Delta Share\n",
    "- Get the data from a query from a Delta share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "275ccdbe-b220-4926-b481-5f871653c764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ydata/.venv/lib/python3.10/site-packages/distributed/client.py:3169: UserWarning: Sending large graph of size 55.65 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDataset \n",
      " \n",
      "\u001B[0m\u001B[1mShape: \u001B[0m(1056320, 10)\n",
      "\u001B[1mSchema: \u001B[0m\n",
      "       Column Variable type\n",
      "0    trans_id           int\n",
      "1  account_id           int\n",
      "2        date           int\n",
      "3        type        string\n",
      "4   operation        string\n",
      "5      amount         float\n",
      "6     balance         float\n",
      "7    k_symbol        string\n",
      "8        bank        string\n",
      "9     account         float\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This method reads all the data records in the table\n",
    "table = connector.read_table(table_name='transactions',\n",
    "                             schema_name='berka',\n",
    "                             share_name='teste')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f13e164e-666b-447d-a1e1-51f6c038b9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDataset \n",
      " \n",
      "\u001B[0m\u001B[1mShape: \u001B[0m(1000, 10)\n",
      "\u001B[1mSchema: \u001B[0m\n",
      "       Column Variable type\n",
      "0    trans_id           int\n",
      "1  account_id           int\n",
      "2        date           int\n",
      "3        type        string\n",
      "4   operation        string\n",
      "5      amount         float\n",
      "6     balance         float\n",
      "7    k_symbol        string\n",
      "8        bank        string\n",
      "9     account         float\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This method reads a sample with number of records = provided sample size\n",
    "table_sample = connector.read_table_sample(table_name='transactions',\n",
    "                                           schema_name='berka',\n",
    "                                           share_name='teste',\n",
    "                                           sample_size=1000)\n",
    "print(table_sample)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
