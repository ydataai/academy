{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample\n",
    "This notebook loads the reconstructed data and upsamples to 15-minute frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 - Imports\n",
    "Load the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/dask_gateway/client.py:21: FutureWarning: format_bytes is deprecated and will be removed in a future release. Please use dask.utils.format_bytes instead.\n",
      "  from distributed.utils import LoopRunner, format_bytes\n"
     ]
    }
   ],
   "source": [
    "from ydata.connectors import LocalConnector, GCSConnector\n",
    "from ydata.utils.formats import read_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 - Auxiliary Functions\n",
    "The auxiliary functions are custom-designed utilities developed for the REE use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocess_data\n",
    "from upsample import upsample_stations\n",
    "from imputation import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Local Connector\n",
    "connector = LocalConnector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reconstructed data for the given device\n",
    "reconstructed = preprocess_data(connector.read_file('whole_year_reconstructed.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Upsample\n",
    "For each device, upsample the timeseries frequency from 1H to 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_upsampled = upsample_stations(reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Upsample Original\n",
    "For the original values, the upsample is done by resampling the original values with 15 minute frequency instead of a random walk upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original data for the given device\n",
    "original = preprocess_data(connector.read_file('train_allmeters.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the original data for 15 minute frequency\n",
    "original_upsampled = resample(original, ts_col='timestamp', ts_freq='15T', partition_by='station')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Store Data\n",
    "Load the reconstruction and the original values with 15 minute frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the credentials\n",
    "credentials = read_json('gcs_credentials.json')\n",
    "\n",
    "# Create the connector for Google Cloud Storage\n",
    "connector = GCSConnector('ydatasynthetic', gcs_credentials=credentials)\n",
    "\n",
    "# Store the reconstructed data upsampled to 15 minutes\n",
    "connector.write_file(reconstructed_upsampled, 'gs://pipelines_artifacts/wind_measurements_pipeline/outputs/reconstructed_upsampled.csv', index=True)\n",
    "\n",
    "# Store the original data upsampled to 15 minutes\n",
    "connector.write_file(original_upsampled, 'gs://pipelines_artifacts/wind_measurements_pipeline/outputs/original_upsampled.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97368d82be436453fc70c6f6344601e0c3d1f89db9828d3df64f3a7192c2ced9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
